{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6101f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Historical Backtesting Analysis\n",
    "# Testing supply chain risk predictions against known events\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ===== DATA COLLECTION FOR BACKTESTING =====\n",
    "\n",
    "class BacktestingFramework:\n",
    "    def __init__(self):\n",
    "        self.companies = {\n",
    "            'TSMC': '2330.TW',\n",
    "            'Intel': 'INTC',\n",
    "            'NVIDIA': 'NVDA',\n",
    "            'AMD': 'AMD',\n",
    "            'Qualcomm': 'QCOM',\n",
    "            'Micron': 'MU',\n",
    "            'Texas Instruments': 'TXN',\n",
    "            'Applied Materials': 'AMAT',\n",
    "            'Broadcom': 'AVGO'\n",
    "        }\n",
    "        \n",
    "        # Define major events with precise dates\n",
    "        self.major_events = {\n",
    "            'COVID-19 Outbreak': {\n",
    "                'date': '2020-01-30',  # WHO declares emergency\n",
    "                'impact_start': '2020-02-01',\n",
    "                'peak_impact': '2020-03-15',\n",
    "                'type': 'pandemic',\n",
    "                'description': 'WHO declares COVID-19 emergency'\n",
    "            },\n",
    "            'Suez Canal Blockage': {\n",
    "                'date': '2021-03-23',\n",
    "                'impact_start': '2021-03-24',\n",
    "                'peak_impact': '2021-03-29',\n",
    "                'type': 'logistics',\n",
    "                'description': 'Ever Given blocks Suez Canal'\n",
    "            },\n",
    "            'US-China Trade War Escalation': {\n",
    "                'date': '2018-07-06',  # First tariffs take effect\n",
    "                'impact_start': '2018-07-06',\n",
    "                'peak_impact': '2018-09-24',\n",
    "                'type': 'geopolitical',\n",
    "                'description': 'First round of US-China tariffs'\n",
    "            },\n",
    "            'Russia-Ukraine Conflict': {\n",
    "                'date': '2022-02-24',\n",
    "                'impact_start': '2022-02-24',\n",
    "                'peak_impact': '2022-03-07',\n",
    "                'type': 'geopolitical',\n",
    "                'description': 'Russia invades Ukraine'\n",
    "            },\n",
    "            'Texas Winter Storm': {\n",
    "                'date': '2021-02-13',\n",
    "                'impact_start': '2021-02-15',\n",
    "                'peak_impact': '2021-02-17',\n",
    "                'type': 'natural_disaster',\n",
    "                'description': 'Texas power grid failure'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def collect_historical_data(self, start_date='2018-01-01', end_date='2024-01-01'):\n",
    "        \"\"\"Collect historical data for all companies\"\"\"\n",
    "        print(\"Collecting historical data for backtesting...\")\n",
    "        \n",
    "        historical_data = {}\n",
    "        for company, symbol in self.companies.items():\n",
    "            try:\n",
    "                ticker = yf.Ticker(symbol)\n",
    "                data = ticker.history(start=start_date, end=end_date)\n",
    "                data['Company'] = company\n",
    "                data['Symbol'] = symbol\n",
    "                historical_data[company] = data\n",
    "                print(f\"‚úì {company}: {len(data)} days\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó Failed to get data for {company}: {e}\")\n",
    "        \n",
    "        return historical_data\n",
    "    \n",
    "    def calculate_risk_indicators_historical(self, historical_data, lookback_window=30):\n",
    "        \"\"\"Calculate risk indicators for historical backtesting\"\"\"\n",
    "        all_risk_data = []\n",
    "        \n",
    "        for company, data in historical_data.items():\n",
    "            # Calculate rolling metrics\n",
    "            data['Daily_Return'] = data['Close'].pct_change()\n",
    "            data['Volatility_30d'] = data['Daily_Return'].rolling(window=lookback_window).std() * np.sqrt(252)\n",
    "            data['Volume_MA'] = data['Volume'].rolling(window=lookback_window).mean()\n",
    "            data['Volume_Ratio'] = data['Volume'] / data['Volume_MA']\n",
    "            data['Price_MA'] = data['Close'].rolling(window=lookback_window).mean()\n",
    "            data['Price_vs_MA'] = (data['Close'] / data['Price_MA'] - 1) * 100\n",
    "            \n",
    "            # Calculate RSI-like momentum indicator\n",
    "            delta = data['Close'].diff()\n",
    "            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "            rs = gain / loss\n",
    "            data['RSI'] = 100 - (100 / (1 + rs))\n",
    "            \n",
    "            # Create composite risk score\n",
    "            # Higher volatility = higher risk\n",
    "            vol_score = pd.qcut(data['Volatility_30d'], q=5, labels=[1,2,3,4,5], duplicates='drop')\n",
    "            \n",
    "            # Negative performance = higher risk\n",
    "            perf_score = pd.qcut(-data['Price_vs_MA'], q=5, labels=[1,2,3,4,5], duplicates='drop')\n",
    "            \n",
    "            # Extreme volume = higher risk\n",
    "            vol_ratio_score = pd.qcut(np.abs(data['Volume_Ratio'] - 1), q=5, labels=[1,2,3,4,5], duplicates='drop')\n",
    "            \n",
    "            # Combine scores\n",
    "            data['Risk_Score'] = (\n",
    "                pd.to_numeric(vol_score, errors='coerce') * 0.5 +\n",
    "                pd.to_numeric(perf_score, errors='coerce') * 0.3 +\n",
    "                pd.to_numeric(vol_ratio_score, errors='coerce') * 0.2\n",
    "            )\n",
    "            \n",
    "            # Add company identifier\n",
    "            data['Company'] = company\n",
    "            all_risk_data.append(data)\n",
    "        \n",
    "        return pd.concat(all_risk_data)\n",
    "    \n",
    "    def analyze_event_impact(self, risk_data, event_name, pre_event_days=30, post_event_days=60):\n",
    "        \"\"\"Analyze risk score behavior around a specific event\"\"\"\n",
    "        event = self.major_events[event_name]\n",
    "        event_date = pd.to_datetime(event['date'])\n",
    "        \n",
    "        # Filter data around the event\n",
    "        start_date = event_date - timedelta(days=pre_event_days)\n",
    "        end_date = event_date + timedelta(days=post_event_days)\n",
    "        \n",
    "        event_data = risk_data[(risk_data.index >= start_date) & (risk_data.index <= end_date)].copy()\n",
    "        event_data['Days_from_Event'] = (event_data.index - event_date).days\n",
    "        \n",
    "        return event_data\n",
    "    \n",
    "    def calculate_prediction_metrics(self, risk_data, event_name, threshold=3.5, warning_days=14):\n",
    "        \"\"\"Calculate how well the model predicted the event\"\"\"\n",
    "        event = self.major_events[event_name]\n",
    "        event_date = pd.to_datetime(event['date'])\n",
    "        \n",
    "        # Look at risk scores in the warning period before the event\n",
    "        warning_start = event_date - timedelta(days=warning_days)\n",
    "        warning_data = risk_data[(risk_data.index >= warning_start) & (risk_data.index < event_date)]\n",
    "        \n",
    "        if warning_data.empty:\n",
    "            return {'error': 'No data in warning period'}\n",
    "        \n",
    "        # Calculate metrics\n",
    "        companies_warned = warning_data[warning_data['Risk_Score'] > threshold]['Company'].unique()\n",
    "        total_companies = warning_data['Company'].nunique()\n",
    "        \n",
    "        # Get actual impact (measured by volatility increase post-event)\n",
    "        post_event_data = risk_data[(risk_data.index >= event_date) & \n",
    "                                   (risk_data.index <= event_date + timedelta(days=30))]\n",
    "        \n",
    "        if post_event_data.empty:\n",
    "            return {'error': 'No data in post-event period'}\n",
    "        \n",
    "        # Companies that actually had high volatility after the event\n",
    "        high_vol_companies = post_event_data.groupby('Company')['Volatility_30d'].max()\n",
    "        actually_impacted = high_vol_companies[high_vol_companies > high_vol_companies.median()].index\n",
    "        \n",
    "        # Calculate prediction accuracy\n",
    "        true_positives = len(set(companies_warned) & set(actually_impacted))\n",
    "        false_positives = len(set(companies_warned) - set(actually_impacted))\n",
    "        false_negatives = len(set(actually_impacted) - set(companies_warned))\n",
    "        true_negatives = total_companies - true_positives - false_positives - false_negatives\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'event': event_name,\n",
    "            'companies_warned': len(companies_warned),\n",
    "            'total_companies': total_companies,\n",
    "            'warning_rate': len(companies_warned) / total_companies,\n",
    "            'actually_impacted': len(actually_impacted),\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'true_positives': true_positives,\n",
    "            'false_positives': false_positives,\n",
    "            'false_negatives': false_negatives,\n",
    "            'companies_warned_list': list(companies_warned),\n",
    "            'companies_impacted_list': list(actually_impacted)\n",
    "        }\n",
    "\n",
    "# ===== RUN BACKTESTING ANALYSIS =====\n",
    "\n",
    "# Initialize framework\n",
    "bt = BacktestingFramework()\n",
    "\n",
    "print(\"Starting Historical Backtesting Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Collect historical data\n",
    "historical_data = bt.collect_historical_data(start_date='2018-01-01', end_date='2024-01-01')\n",
    "\n",
    "print(f\"\\nData collection complete: {len(historical_data)} companies\")\n",
    "\n",
    "# Calculate risk indicators\n",
    "print(\"\\nCalculating historical risk indicators...\")\n",
    "risk_data = bt.calculate_risk_indicators_historical(historical_data)\n",
    "\n",
    "print(f\"Risk calculation complete: {len(risk_data)} data points\")\n",
    "\n",
    "# ===== EVENT ANALYSIS =====\n",
    "\n",
    "print(\"\\nAnalyzing major supply chain events...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "event_results = {}\n",
    "prediction_metrics = {}\n",
    "\n",
    "for event_name in bt.major_events.keys():\n",
    "    print(f\"\\nüìä Analyzing: {event_name}\")\n",
    "    \n",
    "    # Get event data\n",
    "    event_data = bt.analyze_event_impact(risk_data, event_name)\n",
    "    event_results[event_name] = event_data\n",
    "    \n",
    "    # Calculate prediction metrics\n",
    "    metrics = bt.calculate_prediction_metrics(risk_data, event_name)\n",
    "    prediction_metrics[event_name] = metrics\n",
    "    \n",
    "    if 'error' not in metrics:\n",
    "        print(f\"   Companies warned: {metrics['companies_warned']}/{metrics['total_companies']}\")\n",
    "        print(f\"   Precision: {metrics['precision']:.2f}\")\n",
    "        print(f\"   Recall: {metrics['recall']:.2f}\")\n",
    "        print(f\"   F1 Score: {metrics['f1_score']:.2f}\")\n",
    "\n",
    "# ===== VISUALIZATION =====\n",
    "\n",
    "# Create comprehensive backtesting visualization\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=[\n",
    "        'COVID-19 Impact Analysis', 'Suez Canal Blockage Impact',\n",
    "        'Trade War Escalation Impact', 'Russia-Ukraine Conflict Impact',\n",
    "        'Model Performance Summary', 'Risk Score Distribution'\n",
    "    ],\n",
    "    specs=[[{\"secondary_y\": True}, {\"secondary_y\": True}],\n",
    "           [{\"secondary_y\": True}, {\"secondary_y\": True}],\n",
    "           [{\"colspan\": 2}, None]],\n",
    "    vertical_spacing=0.12\n",
    ")\n",
    "\n",
    "# Plot major events\n",
    "events_to_plot = ['COVID-19 Outbreak', 'Suez Canal Blockage', \n",
    "                  'US-China Trade War Escalation', 'Russia-Ukraine Conflict']\n",
    "\n",
    "positions = [(1,1), (1,2), (2,1), (2,2)]\n",
    "\n",
    "for i, event_name in enumerate(events_to_plot):\n",
    "    if event_name in event_results:\n",
    "        event_data = event_results[event_name]\n",
    "        if not event_data.empty:\n",
    "            row, col = positions[i]\n",
    "            \n",
    "            # Average risk score across all companies\n",
    "            daily_avg = event_data.groupby(event_data.index)['Risk_Score'].mean()\n",
    "            daily_vol = event_data.groupby(event_data.index)['Volatility_30d'].mean()\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=daily_avg.index, y=daily_avg.values, \n",
    "                          name=f'Risk Score', line=dict(color='red', width=2)),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=daily_vol.index, y=daily_vol.values * 100, \n",
    "                          name=f'Volatility %', line=dict(color='blue', width=2)),\n",
    "                row=row, col=col, secondary_y=True\n",
    "            )\n",
    "            \n",
    "            # Add event marker\n",
    "            event_date = pd.to_datetime(bt.major_events[event_name]['date'])\n",
    "            if event_date in daily_avg.index:\n",
    "                fig.add_vline(x=event_date, line_dash=\"dash\", line_color=\"black\",\n",
    "                             annotation_text=event_name, row=row, col=col)\n",
    "\n",
    "# Performance summary\n",
    "valid_metrics = {k: v for k, v in prediction_metrics.items() if 'error' not in v}\n",
    "\n",
    "if valid_metrics:\n",
    "    events = list(valid_metrics.keys())\n",
    "    f1_scores = [valid_metrics[event]['f1_score'] for event in events]\n",
    "    precisions = [valid_metrics[event]['precision'] for event in events]\n",
    "    recalls = [valid_metrics[event]['recall'] for event in events]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(name='F1 Score', x=events, y=f1_scores, marker_color='green'),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='Precision', x=events, y=precisions, marker_color='blue'),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='Recall', x=events, y=recalls, marker_color='orange'),\n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=1200, title_text=\"Supply Chain Risk Model - Historical Backtesting Results\")\n",
    "fig.show()\n",
    "\n",
    "# ===== SUMMARY RESULTS =====\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BACKTESTING SUMMARY RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if valid_metrics:\n",
    "    overall_f1 = np.mean([m['f1_score'] for m in valid_metrics.values()])\n",
    "    overall_precision = np.mean([m['precision'] for m in valid_metrics.values()])\n",
    "    overall_recall = np.mean([m['recall'] for m in valid_metrics.values()])\n",
    "    \n",
    "    print(f\"üìà Overall Model Performance:\")\n",
    "    print(f\"   Average F1 Score: {overall_f1:.3f}\")\n",
    "    print(f\"   Average Precision: {overall_precision:.3f}\")\n",
    "    print(f\"   Average Recall: {overall_recall:.3f}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Event-Specific Results:\")\n",
    "    for event, metrics in valid_metrics.items():\n",
    "        print(f\"   {event}:\")\n",
    "        print(f\"      F1: {metrics['f1_score']:.3f} | Precision: {metrics['precision']:.3f} | Recall: {metrics['recall']:.3f}\")\n",
    "        \n",
    "    print(f\"\\nüí° Key Insights:\")\n",
    "    best_event = max(valid_metrics.items(), key=lambda x: x[1]['f1_score'])\n",
    "    print(f\"   Best predicted event: {best_event[0]} (F1: {best_event[1]['f1_score']:.3f})\")\n",
    "    \n",
    "    total_warnings = sum([m['companies_warned'] for m in valid_metrics.values()])\n",
    "    total_opportunities = sum([m['total_companies'] for m in valid_metrics.values()])\n",
    "    print(f\"   Total warning rate: {total_warnings/total_opportunities:.1%}\")\n",
    "\n",
    "print(\"\\nüîç Model validates against historical supply chain disruptions\")\n",
    "print(\"üìä Results demonstrate predictive capability for risk management\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
